[Back to Unit overview](./Unit1.md)

# Ethics in the age of AI

## Brief
Read Correa et al. (2023) and Deckard (2023).

From late 2022, generative AI has taken the world by storm, and there is no field of activity that has not been impacted in some way. This is so much truer for Computer Science, which is where it all began. It is important to realise, however, that AI itself is nothing new, per se; and if the renaissance of the field after the ‘winter’ of the 1980s has been slow but constant, today there is the need of a different set of rules.

In the Correa et al (2023) paper, the authors state that “a lot of work is taking place to define the values and ideas that should guide AI advances. A key challenge, however, lies in establishing a consensus on these values, given the diverse perspectives of various stakeholders worldwide and the abstraction of normative discourse. Researchers and policy makers need better tools to catalogue and compare AI governance documents from around the world and to identify points of divergence and commonality.”

After reviewing the article and reading how different countries across the world deal with the generative AI revolution, discuss your views on the subject and recommend what you think could be a suitable course of action. You should justify your stance by also reviewing any papers included in this study or other relevant literature (additional links to industry have been provided as ‘Other Resources’ to the module). Your discussion should also highlight the impact your actions would have on applicable legal, social and professional issues. Please note that there is no right or wrong answer here, this exercise is to help you evaluate the legal, social ethical and professional issues that affect computing professionals in industry.

## Reflection

The fifth industrial revolution, or Industry 5.0 is defined as the merging or the physical and virtual world, where technology is Human-Centric, Sustainable, and Resilient (Xu et al., 2021; Coelho et al., 2023). As technology and computing has a greater impact on human life, it is important that the ethics of development and use are considered to ensure the impact is as a minimum, not negative (Finn and Shilton, 2023). This is essential when considering Human Centered AI (Martini, Bellisario and Coletti, 2024).

Ethical values vary across cultures, as different groups of people prioritise different values (Jakesch et al., 2022), yet AI and Information Technology transcends national and cultural borders. This is why the work by Corrêa et al. (2023) is important, looking at how the ethics of AI and associated governance is being apportioned around the world. While previous meta-analysis cited Corrêa et al. (2023) either focused on western publications, or excluded developing nations, their work attempted to access as many nations as possible, including developing nations. Although their work suffers from similar criticism they they levy against previous work. Corrêa et al. (2023) limit themselves to publications in five languages (English, Portuguese. French, German and Spanish), meaning some African, Asian and Middle East publications could be missed.

Despite these shortcomings, Corrêa et al. (2023) results mostly agreed with previous studies, where the top 10 principles for ethics and governance in AI were identified as:
1. Transparency
2. Reliability
3. Fairness/Non-discrimination
4. Privacy
5. Accountability
6. Democratic values / Technical Sovereignty
7. Diversity / Inclusion
8. Beneficence
9. Dignity / Human rights
10. Education

It is not surprising that the institutions publishing the most regarding ethics in AI, are Government Institutions, as these have a duty of care towards their own citizens. However, in order to achieve an international consensus on AI ethics, requires the work of multi-national organisations, taking into consideration the cultures of all nations the organisation operates in. It is therefore reassuring to see that Private Corporations have published as much on AI ethics as Government Institutions, followed by NGO's and Non-profits.

One organisation that has the ability to consider multi-national input, and enforce any breaches in ethics, is the European Union (EU). The EU have produced legislation governing AI (European Union, 2021) which followed guidance from an expert working group (High-Level Expert Group on Artificial Intelligence, 2018). The high-level working group identified five fundamental rights that must be adhered to:
1. Respect for Human dignity.
2. Freedom of the individual.
3. Respect for Democracy, justice and the rule of law.
4. Equality, non-discrimination and solidarity.
5. Citizens rights. 

These five rights are then used to shape four ethical principles to be considered when developing AI:
1. Respect for Human autonomy.
2. Prevention of harm.
3. Fairness.
4. Explicability. 

These rights and ethical principles agree with the findings of Corrêa et al. (2023), which is most likely due to 31% of the studies examined originated from a European country, however it is also reassuring that when including other nations, these principles still hold.

Ciobanu and Meșniță (2022) take the four ethical principles from the High-Level Expert Group on Artificial Intelligence (2018) and propose a two layered approach, where Ethics is embedded from conception of AI. Their two layers are AI Embedded Ethics by Design (AI EED), where the developer and data scientists can ensure the four ethical principles are adhered to before release. The second layer is AI Desired State Configuration (AI DSC), where the AI system is monitored post implementation. Ciobanu and Meșniță (2022) argue that given the characteristics of Industry 5.0, any AI system needs to be managed by humans in a way it can be monitored, measured on specific criteria, actioned and further developed.

The concept of AI EED is similar to the principle of "Secure by Design" (Government Security Group, 2025), which is used to protect users from un-ethical actors.

Of course, the European Union only has the authority to legislate over organisations acting within EU, and cannot act to protect non-EU citizens outside the EU. For this, AI developers should look to the International Standards Organisation, and their standard 42001(ISO/IEC 42001, 2023). Whilst not mandatory, ISO certification goes a long way to providing assurance to end users that the product being used is well governed, safe and ethically implemented.

My personal recommendation to ensure Artificial Intelligence remains true to the Human-Centric and Sustainable values of Industry 5.0, is embed ethics at design (Ciobanu and Meșniță, 2022). The development and then post release governance should follow a set of internationally recognised ethical standards (ISO/IEC 42001, 2023), and be enforced through strong legislation (European Union, 2021). This will ensure, as far as is reasonable, AI does not have a negative impact on society.

There are of course challenges to implementing ethics in computer science. There will always be "Black Hat Hackers" (Poudel and Karna, 2024), and there is very little that can be done to prevent malicious development and use of AI (Blauth, Gstrein and Zwitter, 2022), thus reaffirming the need for strong cyber security, and transparency of commercial AI products, allowing users to know and understand that the product being used has been developed and governed in an ethical manner.

Finally, Deckard (2023) promotes the idea AI Ethics as a profession. This is is a role that can either be recruited into, or additional responsibility absorbed into an existing role (e.g. Governance lead), in much the same way that a Clinical Safety Officer is required for the development and deployment of digital technologies in Healthcare (NHS England, 2018a, 2018b). This will will provide an organisation developing or using AI with transparency and assurance ethical principles are upheld.

## References

Blauth, T.F., Gstrein, O.J. and Zwitter, A. (2022) ‘Artificial Intelligence Crime: An Overview of Malicious Use and Abuse of AI’, _IEEE Access_, 10, pp. 77110–77122. Available at: [https://doi.org/10.1109/ACCESS.2022.3191790](https://doi.org/10.1109/ACCESS.2022.3191790).

Ciobanu, A.C. and Meșniță, G. (2022) ‘AI Ethics for Industry 5.0 – From Principles to Practice’, in _Proceedings of Interoperability for Enterprise Systems and Applications Workshops_. Valencia, Spain. Available at: [https://ceur-ws.org/Vol-3214/](https://ceur-ws.org/Vol-3214/).

Coelho, P. _et al._ (2023) ‘Industry 5.0: The Arising of a Concept’, _Procedia Computer Science_, 217, pp. 1137–1144. Available at: [https://doi.org/10.1016/j.procs.2022.12.312](https://doi.org/10.1016/j.procs.2022.12.312).

Corrêa, N.K. _et al._ (2023) ‘Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance’, _Patterns_, 4(10). Available at: [https://doi.org/10.1016/j.patter.2023.100857](https://doi.org/10.1016/j.patter.2023.100857).

Deckard, R. (2023) _What are ethics in AI? / BCS_. Available at: [https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/](https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/) (Accessed: 20 October 2025).

European Union (2021) _Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE (ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION LEGISLATIVE ACTS_. Available at: [https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206](https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206) (Accessed: 22 October 2025).

Finn, M. and Shilton, K. (2023) ‘Ethics governance development: The case of the Menlo Report’, _Social Studies of Science_, 53(3), pp. 315–340. Available at: [https://doi.org/10.1177/03063127231151708](https://doi.org/10.1177/03063127231151708).

Government Security Group (2025) _Secure by Design Principles_, _UK Government Security - Beta_. Available at: [https://www.security.gov.uk/policy-and-guidance/secure-by-design/principles/](https://www.security.gov.uk/policy-and-guidance/secure-by-design/principles/) (Accessed: 22 October 2025).

High-Level Expert Group on Artificial Intelligence (2018) _Ethics Guidelines for Trustworthy AI_. Text. Available at: [https://ec.europa.eu/futurium/en/ai-alliance-consultation](https://ec.europa.eu/futurium/en/ai-alliance-consultation) (Accessed: 22 October 2025).

ISO/IEC 42001 (2023) ‘ISO/IEC 42001:2023 Information Technology  - Artificial Inelligence - Management system’. Available at: [https://www.iso.org/standard/42001](https://www.iso.org/standard/42001) (Accessed: 23 October 2025).

Jakesch, M. _et al._ (2022) ‘How Different Groups Prioritize Ethical Values for Responsible AI’, in _Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_. New York, NY, USA: Association for Computing Machinery (FAccT ’22), pp. 310–323. Available at: [https://doi.org/10.1145/3531146.3533097](https://doi.org/10.1145/3531146.3533097).

Martini, B., Bellisario, D. and Coletti, P. (2024) ‘Human-Centered and Sustainable Artificial Intelligence in Industry 5.0: Challenges and Perspectives’, _Sustainability_, 16(13), p. 5448. Available at: [https://doi.org/10.3390/su16135448](https://doi.org/10.3390/su16135448).

NHS England (2018a) ‘DCB0129: Clinical Risk Management: its Application in the Manufacture of Health IT Systems’. NHS Digital.

NHS England (2018b) ‘DCB0160: Clinical Risk Management: its Application in the Deployment and Use of Health IT Systems’. NHS Digital.

Poudel, B. and Karna, S.K. (2024) ‘What Influences a Hacker to be a Black Hat?’, _Medicon Engineering Themes_, 6(6). Available at: [https://doi.org/10.55162/MCET.06.215](https://doi.org/10.55162/MCET.06.215).

Xu, X. _et al._ (2021) ‘Industry 4.0 and Industry 5.0—Inception, conception and perception’, _Journal of Manufacturing Systems_, 61, pp. 530–535. Available at: [https://doi.org/10.1016/j.jmsy.2021.10.006](https://doi.org/10.1016/j.jmsy.2021.10.006).
