[Back to Assignment](./Assignment1.md)

# Initial Post
_By Mark Collins, Saturday 3 May 2025_

Information and data is the new currency of the modern world (Teboul, 2021). This currency can only have *Value* to an organisation if it is *Valid* (i.e. veracity) (Alsaig, Alagar and Ormandjieva, 2018). Artificial Intelligence can assist an organisation on two fronts with regards to managing *big data*.

First, with the vast *Volume* of data, and *Velocity* in which said data can evolve, Artificial Intelligence can be a useful tool to process in near real time, providing business makers with up to date information (Teboul, 2021). Second, Artificial Intelligence can play a critical role in keeping the data secure (Hero et al., 2023).

Combining AI with the processing and protection of an organisations data poses a number of risks. The ability to successfully use AI depends on the quality of the training data, particularly if the training data is representative of the data being processed, or if it has been "poisoned" by malicious adversaries (Hero et al., 2023).

Additionally, if AI has been used to deploy statistical analysis of network activity to identify unusual and malicious activity, there is a risk that tolerances are too tight, and too many false positives are detected. Alternatively, if tolerances are widened, then malicious activity can go undetected (Hero et al., 2023).

This is where the Data Scientist is an essential resource within an organisation. The use of Data Science can be used to identify the sweet-spot suggested by Hero et al. (2023), using game theory, as well as processing, cleaning and validating any training data used for the Machine Learning Model.

**Word Count**: 241

**References**
Alsaig, A., Alagar, V. and Ormandjieva, O. (2018) ‘A Critical Analysis of the V-Model of Big Data’, in _2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE). 2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)_, pp. 1809–1813. Available at: https://doi.org/10.1109/TrustCom/BigDataSE.2018.00273.

Hero, A. et al. (2023) ‘Statistics and Data Science for Cybersecurity’, _Harvard Data Science Review_, 5(1). Available at: https://doi.org/10.1162/99608f92.a42024d0.

Teboul, B. (2021) ‘The challenges of the convergence of Data, AI, Cloud, Blockchain, IoT and Cybersecurity’, _European Scientist_, 17 December. Available at: https://www.europeanscientist.com/en/features/the-challenges-of-the-convergence-of-data-ai-cloud-blockchain-iot-and-cybersecurity/ (Accessed: 29 April 2025).

# Peer Response 1
_By Farhad Karimov, Sunday 4 May 2025_

Your post shows appreciation for your thoughtful message. The modern enterprise depends on data-driven decision-making which  matches your definition of data as the new currency. Your explanation of the “4Vs” of big  data—volume, velocity, veracity, and value—and the role of AI in navigating these dimensions  was very much appreciated.

Your observation about AI's susceptibility to adversarial data poisoning stands as a vital  point. Hero et al. (2023) correctly states that the quality and integrity of training data  serve as fundamental factors for maintaining effective and trustworthy AI models. AI systems will either spread errors or become  manipulable when data cleaning and validation procedures are inadequate especially when dealing with cybersecurity-sensitive areas.

Prof. Williams (2025) reinforced in his seminar that data scientists must perform data preparation and cleaning while  maintaining ethical and legal compliance throughout the data pipeline. He explained this as a “strategic role”  which requires both technical expertise and professional accountability to protect digital systems.

Your explanation of tolerance calibration in  AI-driven intrusion detection systems stands out as particularly significant. Security teams face two major problems when dealing with false  positives because excessive alerts overwhelm them while undetected threats can pass through false negatives. Hero et  al. (2023) recommend game-theoretic methods for finding the optimal detection thresholds which data scientists  can optimize using simulation and historical data analysis to achieve.

Your post successfully demonstrates how data science acts as  the fundamental foundation for building secure and effective AI systems. The convergence of AI and cybersecurity will create an  increasing need for data scientists who possess both ethical standards and technical expertise.

References:

Hero, A., Kar, S., Moura, J., Neil, J., Poor, H. V., Turcotte, M., & Xi, B. (2023). Statistics and data science for cybersecurity. Harvard Data Science Review, 5(1)

Tebout, B. (2021). The challenges of the convergence of Data, AI, Cloud, Blockchain, IoT and Cybersecurity. European Scientist.

# Peer Response 2
_By Nelson Akaffou, Tuesday 6 May 2025_

Thank you, Mark, your post effectively highlights the dual role of AI in managing big data, enhancing real-time processing while securing sensitive information. I agree that data validity and model accuracy are critical, particularly in cybersecurity, where false positives or negatives can have significant consequences (Hero et al., 2023).
However, I believe the discussion could be expanded to address ethical considerations. AI-driven data analysis, while powerful, can inadvertently reinforce biases if training data isn't thoroughly audited (Mehrabi et al., 2021). For instance, algorithmic bias in fraud detection could disproportionately flag certain demographics, leading to unfair outcomes (Barocas & Selbst, 2016). Additionally, over-reliance on AI without human oversight risks creating blind spots, especially when adversaries adapt to bypass automated defences (Brundage et al., 2018).
The role of the Data Scientist, as you mentioned, is indeed crucial, but organisations must also foster interdisciplinary collaboration. Cybersecurity experts, ethicists, and business leaders should work alongside data scientists to ensure AI systems are not only efficient but also fair and resilient (Floridi et al., 2018). A layered approach—combining AI with human judgment—might strike the right balance between automation and critical oversight (Holzinger et al., 2019).

Word Count: 192 words
References

Barocas, S., & Selbst, A. D. (2016). Big data's disparate impact. California Law Review, 104(3), 671-732.

Brundage, M., et al. (2018). The malicious use of artificial intelligence: Forecasting, prevention, and mitigation. arXiv preprint arXiv:1802.07228.

Floridi, L., et al. (2018). AI4People—An ethical framework for a good AI society. Minds and Machines, 28(4), 689-707.

Holzinger, A., et al. (2019). Causability and explainability of AI in medicine. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 9(4), e1312.

Mehrabi, N., et al. (2021). A survey on bias and fairness in machine learning. ACM Computing Surveys, 54(6), 1-35.

# Peer Responce 3
_By Tobias Zeier, Saturday 10 May 2025_

Mark, your post resonated with me, particularly the emphasis on AI’s dual role in managing data volume and enhancing cybersecurity. However, I think we must question the assumption that AI can reliably handle such tasks without robust human oversight. While Hero et al. (2023) highlight AI’s statistical capabilities for intrusion detection, there is a real risk of overestimating automation in contexts where adversaries are constantly evolving and datasets become outdated or compromised.

Farhad’s emphasis on the data scientist’s role is insightful, although I believe this position is increasingly burdened by competing demands such as delivering fast results while ensuring ethical compliance (Floridi et al., 2018). In practice, this can lead to compromised data quality and insufficient validation under business pressures which ultimately will lead to wrong decisions.

Nelson makes an important point on bias. I would go further to argue that algorithmic bias is not merely a technical glitch. It reflects deeper structural inequalities embedded in data collection processes (Barocas and Selbst, 2016). AI, if poorly governed, risks maintaining these biases at scale.

Ultimately, AI should support, not replace, human decision-making. Ethical governance and interdisciplinary collaboration must become central to any data-driven strategy.

Word count: 193

References

Barocas, S. and Selbst, A.D. (2016) ‘Big data’s disparate impact’, *California Law Review*, 104(3), pp. 671-732. Available at: https://doi.org/10.15779/Z38BG31

Floridi, L., Cowls, J., Beltrametti, M., Chatila, R., Chazerand, P., Dignum, V., Luetge, C., Madelin, R., Pagallo, U., Rossi, F. and Schafer, B. (2018) ‘AI4People-An ethical framework for a good AI society: Opportunities, risks, principles, and recommendations’, *Minds and Machines*, 28(4), pp. 689-707. Available at: https://doi.org/10.1007/s11023-018-9482-5

Hero, A., Kar, S., Moura, J., Neil, J., Poor, H.V., Turcotte, M. and Xi, B. (2023) ‘Statistics and data science for cybersecurity’, *Harvard Data Science Review*, 5(1). Available at: https://doi.org/10.1162/99608f92.a42024d0

Teboul, B. (2021) *The challenges of the convergence of Data, AI, Cloud, Blockchain, IoT and Cybersecurity*. Available at: https://www.europeanscientist.com/en/features/the-challenges-of-the-convergence-of-data-ai-cloud-blockchain-iot-and-cybersecurity/ [Accessed 10 May 2025].

# Summary Post
_By Mark Collins, Friday 16 May 2025_
Farhad, Nelson and Tobi.

Thank you for your thoughtful responses. It is clear that this convergence of AI, Data Science and Cyber Security is a rapidly growing area of research and application of computer science (Teboul, 2021). You have all made excellent points in that to protect data used in an organisation, and to ensure the data used to train AI has been managed with good governance (Kroll, 2018; Birkstedt et al., 2023; Dunleavy and Margetts, 2025).

The use of AI in organisations is rapidly growing and the good governance is limited to not only the implementation (Taeihagh, 2021), but also in the datasets used to train the models (Zając et al., 2023). The role of the Data Scientist is essential in the processing of data used to train the AI model. Indeed the stages required to train an AI model (Amershi et al., 2019; Zając et al., 2023), are essentially the same steps in the OSEMN model of Data Science (Janssens, 2021).

Of course, the data used in training the AI model must be protected through good governance and Cyber Security principles. As skilled as the Data Scientist may be in processing and cleaning the training dataset, there is still the risk of malicious poisoning (Yerlikaya and Bahtiyar, 2022).

Finally, the implementation and use of AI in Data Science (Hassani and Silva, 2023) and Cyber Security (Hero et al., 2023) closes the loop. While there is enormous potential to using AI, it has its drawbacks such as AI Hallucinations (Salvagno, Taccone and Gerli, 2023) and any user must be aware of these limitations. Indeed Salvagno, Taccone and Gerli (2023) provide a diagram indicating the use of AI can follow a modified Dunning-Kruger effect (Kruger and Dunning, 1999), showing how as one becomes more proficient in understanding AI, ones confidence in it abilities drop, until a point where a user can appreciate AI as a tool to assist in their work, and not replace it.

In conclusion, the convergence of AI, Data Science, and Cyber Security is demonstrated by the fact that training an AI model is a sub-set of data science. While AI has its use in the implementation of Cyber Security, the data used to train the model, and just as importantly, processed by the model must be protected through Cyber Security principles. This is ultimately achieved by adopting good governance practices, some of which are yet to be defined in this rapidly evolving field of computer science.

**Word Count**: 371

**References**

Amershi, S. et al. (2019) ‘Software Engineering for Machine Learning: A Case Study’, in *2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)*, pp. 291–300. Available at: https://doi.org/10.1109/ICSE-SEIP.2019.00042.

Birkstedt, T. et al. (2023) ‘AI governance: themes, knowledge gaps and future agendas’, *Internet Research*, 33(7), pp. 133–167. Available at: https://doi.org/10.1108/INTR-01-2022-0042.

Dunleavy, P. and Margetts, H. (2025) ‘Data science, artificial intelligence and the third wave of digital era governance’, *Public Policy and Administration*, 40(2), pp. 185–214. Available at: https://doi.org/10.1177/09520767231198737.

Hassani, H. and Silva, E.S. (2023) ‘The Role of ChatGPT in Data Science: How AI-Assisted Conversational Interfaces Are Revolutionizing the Field’, *Big Data and Cognitive Computing*, 7(2), p. 62. Available at: https://doi.org/10.3390/bdcc7020062.

Hero, A. et al. (2023) ‘Statistics and Data Science for Cybersecurity’, *Harvard Data Science Review*, 5(1). Available at: https://doi.org/10.1162/99608f92.a42024d0.

Janssens, J. (2021) *Data Science at the Command Line*. 2nd edn. Sebastopol, CA: O’Reilly.

Kroll, J.A. (2018) ‘Data Science Data Governance [AI Ethics]’, *IEEE Security & Privacy*, 16(6), pp. 61–70. Available at: https://doi.org/10.1109/MSEC.2018.2875329.

Kruger, J. and Dunning, D. (1999) ‘Unskilled and unaware of it: How difficulties in recognizing one’s own incompetence lead to inflated self-assessments’, *Journal of Personality and Social Psychology*, 77(6), pp. 1121–1134. Available at: https://doi.org/10.1037/0022-3514.77.6.1121.

Salvagno, M., Taccone, F.S. and Gerli, A.G. (2023) ‘Artificial intelligence hallucinations’, *Critical Care*, 27(1), p. 180. Available at: https://doi.org/10.1186/s13054-023-04473-y.

Taeihagh, A. (2021) ‘Governance of artificial intelligence’, *Policy and Society*, 40(2), pp. 137–157. Available at: https://doi.org/10.1080/14494035.2021.1928377.

Teboul, B. (2021) ‘The challenges of the convergence of Data, AI, Cloud, Blockchain, IoT and Cybersecurity’, *European Scientist*, 17 December. Available at: https://www.europeanscientist.com/en/features/the-challenges-of-the-convergence-of-data-ai-cloud-blockchain-iot-and-cybersecurity/ (Accessed: 29 April 2025).

Yerlikaya, F.A. and Bahtiyar, Ş. (2022) ‘Data poisoning attacks against machine learning algorithms’, *Expert Systems with Applications*, 208, p. 118101. Available at: https://doi.org/10.1016/j.eswa.2022.118101.

Zając, H.D. et al. (2023) ‘Ground Truth Or Dare: Factors Affecting The Creation Of Medical Datasets For Training AI’, in *Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society*. New York, NY, USA: Association for Computing Machinery (AIES ’23), pp. 351–362. Available at: https://doi.org/10.1145/3600211.3604766.